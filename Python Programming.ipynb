{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDkKQkqKZi+mKjqOjyNytn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"cbDKQApyaRUn","executionInfo":{"status":"ok","timestamp":1707726231174,"user_tz":-330,"elapsed":14,"user":{"displayName":"Rishikesh Bade","userId":"12290714623987359329"}}},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n"]},{"cell_type":"code","source":["def scrape_data(url):\n","    # Send an HTTP request to the URL\n","    response = requests.get(url)\n","\n","    # Check if the request was successful\n","    if response.status_code == 200:\n","        # Parse the HTML content\n","        soup = BeautifulSoup(response.text, 'html.parser')\n","\n","        # Write your scraping logic here\n","\n","        # For demonstration purposes, let's assume we're extracting the title of the page\n","        page_title = soup.title.text\n","\n","        return page_title\n","    else:\n","        print(\"Failed to retrieve data from\", url)\n","        return None"],"metadata":{"id":"x3yQ2Sj-ammq","executionInfo":{"status":"ok","timestamp":1707726243309,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rishikesh Bade","userId":"12290714623987359329"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["queries = [\n","    \"Identify the industry in which Canoo operates, along with its size, growth rate, trends, and key players.\",\n","    \"Analyze Canoo's main competitors, including their market share, products or services offered, pricing strategies, and marketing efforts.\",\n","    \"Identify key trends in the market, including changes in consumer behavior, technological advancements, and shifts in the competitive landscape.\",\n","    \"Gather information on Canoo's financial performance, including its revenue, profit margins, return on investment, and expense structure.\"\n","]"],"metadata":{"id":"YrNuASRcasTJ","executionInfo":{"status":"ok","timestamp":1707726265231,"user_tz":-330,"elapsed":451,"user":{"displayName":"Rishikesh Bade","userId":"12290714623987359329"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["urls = [\n","    \"https://example.com/query1\",\n","    \"https://example.com/query2\",\n","    \"https://example.com/query3\",\n","    \"https://example.com/query4\"\n","]"],"metadata":{"id":"k-LDPyWuaxSs","executionInfo":{"status":"ok","timestamp":1707726285382,"user_tz":-330,"elapsed":470,"user":{"displayName":"Rishikesh Bade","userId":"12290714623987359329"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["with open('scraped_data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n","    csvwriter = csv.writer(csvfile)\n","    csvwriter.writerow(['Query', 'Scraped Data'])\n","\n","    # Iterate through each query and URL pair\n","    for query, url in zip(queries, urls):\n","        # Scraping data from the URL\n","        scraped_data = scrape_data(url)\n","\n","        # Writing the query and scraped data to the CSV file\n","        csvwriter.writerow([query, scraped_data])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nc709HXWa2-F","executionInfo":{"status":"ok","timestamp":1707726308244,"user_tz":-330,"elapsed":1353,"user":{"displayName":"Rishikesh Bade","userId":"12290714623987359329"}},"outputId":"8a8e7703-5fc9-49e4-e2ad-736d11bed0c8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Failed to retrieve data from https://example.com/query1\n","Failed to retrieve data from https://example.com/query2\n","Failed to retrieve data from https://example.com/query3\n","Failed to retrieve data from https://example.com/query4\n"]}]},{"cell_type":"code","source":["print(\"Data scraping and writing to CSV file completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfFX9HFva_ZB","executionInfo":{"status":"ok","timestamp":1707726342660,"user_tz":-330,"elapsed":482,"user":{"displayName":"Rishikesh Bade","userId":"12290714623987359329"}},"outputId":"7ed43479-4f9e-413a-de91-99a5ccc04881"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Data scraping and writing to CSV file completed.\n"]}]}]}